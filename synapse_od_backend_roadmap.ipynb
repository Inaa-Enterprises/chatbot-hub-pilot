{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Synapse-OD Backend Development Roadmap\n",
    "\n",
    "This notebook outlines the complete backend development strategy for Synapse-OD, focusing on using free cloud services and Google Vertex AI for model training. The roadmap prioritizes backend implementation while maximizing automation.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Synapse-OD is a cyberpunk-themed web application for creating and managing AI assistants powered by Google's Gemini models. The application requires a robust backend to support various features including:\n",
    "\n",
    "- User authentication and authorization\n",
    "- AI chat functionality with multiple personas\n",
    "- File and URL processing for learning materials\n",
    "- Child bot creation and management\n",
    "- Administrative analytics and monitoring\n",
    "\n",
    "## Development Priorities\n",
    "\n",
    "1. Core Backend Infrastructure\n",
    "2. Authentication System\n",
    "3. AI Interaction Services\n",
    "4. Content Processing Pipeline\n",
    "5. Child Bot Management\n",
    "6. Admin Analytics & Monitoring\n",
    "7. Security Implementation\n",
    "8. Deployment & DevOps\n"
   ],
   "id": "85d2d96ff1620d2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the core tech stack and dependencies\n",
    "import json\n",
    "\n",
    "# Define our technology stack for backend development\n",
    "tech_stack = {\n",
    "    \"language\": \"Python 3.11+\",\n",
    "    \"frameworks\": {\n",
    "        \"primary\": \"FastAPI\",\n",
    "        \"secondary\": \"Flask (for specific microservices if needed)\"\n",
    "    },\n",
    "    \"databases\": {\n",
    "        \"primary\": \"MongoDB Atlas (free tier)\",\n",
    "        \"vector_store\": \"Pinecone (free tier)\",\n",
    "        \"caching\": \"Redis (free tier on Redis Cloud)\"\n",
    "    },\n",
    "    \"cloud_services\": {\n",
    "        \"hosting\": \"Google Cloud Run (free tier quota)\",\n",
    "        \"storage\": \"Google Cloud Storage (free tier quota)\",\n",
    "        \"ml_platform\": \"Vertex AI (free credits for new accounts)\",\n",
    "        \"functions\": \"Google Cloud Functions (free tier quota)\"\n",
    "    },\n",
    "    \"authentication\": {\n",
    "        \"provider\": \"Firebase Authentication (free tier)\",\n",
    "        \"method\": \"JWT tokens\"\n",
    "    },\n",
    "    \"messaging\": {\n",
    "        \"queue\": \"Google Cloud Pub/Sub (free tier quota)\"\n",
    "    },\n",
    "    \"monitoring\": {\n",
    "        \"logging\": \"Google Cloud Logging (free tier quota)\",\n",
    "        \"analytics\": \"Google Analytics (free)\"\n",
    "    },\n",
    "    \"version_control\": \"GitHub\",\n",
    "    \"ci_cd\": \"GitHub Actions (free for public repositories)\"\n",
    "}\n",
    "\n",
    "print(json.dumps(tech_stack, indent=2))\n"
   ],
   "id": "1e88b9530ba0473d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Core Backend Infrastructure\n",
    "\n",
    "### 1.1 Project Structure\n",
    "\n",
    "We'll structure our backend as a combination of monolithic API (for core services) and microservices (for specialized processing tasks), using FastAPI as our primary framework.\n",
    "\n",
    "```\n",
    "synapse-od-backend/\n",
    "├── app/\n",
    "│   ├── api/\n",
    "│   │   ├── v1/\n",
    "│   │   │   ├── auth.py\n",
    "│   │   │   ├── chat.py\n",
    "│   │   │   ├── upload.py\n",
    "│   │   │   ├── child_bots.py\n",
    "│   │   │   └── admin.py\n",
    "│   ├── core/\n",
    "│   │   ├── config.py\n",
    "│   │   ├── security.py\n",
    "│   │   └── database.py\n",
    "│   ├── models/\n",
    "│   │   ├── user.py\n",
    "│   │   ├── chat.py\n",
    "│   │   ├── persona.py\n",
    "│   │   ├── child_bot.py\n",
    "│   │   └── admin.py\n",
    "│   ├── services/\n",
    "│   │   ├── ai_service.py\n",
    "│   │   ├── file_service.py\n",
    "│   │   ├── analytics_service.py\n",
    "│   │   └── notification_service.py\n",
    "│   ├── utils/\n",
    "│   │   ├── logging.py\n",
    "│   │   ├── validators.py\n",
    "│   │   └── helpers.py\n",
    "│   └── main.py\n",
    "├── microservices/\n",
    "│   ├── file_processor/\n",
    "│   │   └── main.py\n",
    "│   ├── url_processor/\n",
    "│   │   └── main.py\n",
    "│   └── model_trainer/\n",
    "│       └── main.py\n",
    "├── tests/\n",
    "├── .env.example\n",
    "├── requirements.txt\n",
    "├── Dockerfile\n",
    "└── docker-compose.yml\n",
    "```\n"
   ],
   "id": "26368f313a0964cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define our API endpoints structure\n",
    "api_endpoints = {\n",
    "    \"auth\": {\n",
    "        \"POST /api/v1/auth/register\": \"Register a new user\",\n",
    "        \"POST /api/v1/auth/login\": \"Authenticate user and issue JWT\",\n",
    "        \"POST /api/v1/auth/logout\": \"Invalidate JWT\",\n",
    "        \"GET /api/v1/auth/me\": \"Get current user profile\",\n",
    "        \"PUT /api/v1/auth/me\": \"Update user profile\",\n",
    "        \"POST /api/v1/auth/social/{provider}\": \"Handle social login callbacks\"\n",
    "    },\n",
    "    \"chat\": {\n",
    "        \"POST /api/v1/chat\": \"Send message to AI and get response\",\n",
    "        \"GET /api/v1/chat/personas\": \"Get list of available personas\",\n",
    "        \"GET /api/v1/chat/history\": \"Get chat history (paginated)\",\n",
    "        \"DELETE /api/v1/chat/history/{chat_id}\": \"Delete a specific chat\"\n",
    "    },\n",
    "    \"upload\": {\n",
    "        \"POST /api/v1/upload/file\": \"Upload and process a file\",\n",
    "        \"POST /api/v1/upload/url\": \"Submit and process a URL\",\n",
    "        \"GET /api/v1/upload/status/{job_id}\": \"Check processing status\"\n",
    "    },\n",
    "    \"child_bots\": {\n",
    "        \"POST /api/v1/child-bots\": \"Create a new child bot\",\n",
    "        \"GET /api/v1/child-bots\": \"List user's child bots\",\n",
    "        \"GET /api/v1/child-bots/{bot_id}\": \"Get a specific child bot\",\n",
    "        \"PUT /api/v1/child-bots/{bot_id}\": \"Update a child bot\",\n",
    "        \"DELETE /api/v1/child-bots/{bot_id}\": \"Delete a child bot\"\n",
    "    },\n",
    "    \"admin\": {\n",
    "        \"GET /api/v1/admin/analytics\": \"Get platform usage analytics\",\n",
    "        \"GET /api/v1/admin/api-status\": \"Get API usage status\",\n",
    "        \"GET /api/v1/admin/model-lms\": \"Get child bot performance data\",\n",
    "        \"GET /api/v1/admin/query-logs\": \"Get query logs for QC\",\n",
    "        \"PUT /api/v1/admin/query-logs/{log_id}/status\": \"Update query log status\",\n",
    "        \"POST /api/v1/admin/query-logs/cleanup\": \"Trigger data cleanup\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(api_endpoints, indent=2))\n"
   ],
   "id": "91982ff3b0d57e56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Authentication System\n",
    "\n",
    "We'll implement a robust authentication system using Firebase Authentication (free tier) with JWT for session management.\n",
    "\n",
    "### 2.1 Authentication Flow\n",
    "\n",
    "1. User registers or logs in via the frontend\n",
    "2. Firebase Authentication handles credential verification\n",
    "3. Backend verifies Firebase ID token and issues a custom JWT\n",
    "4. Frontend stores JWT and includes it in the Authorization header for subsequent requests\n",
    "5. Backend validates JWT for protected endpoints\n",
    "\n",
    "### 2.2 Implementation Steps\n",
    "\n",
    "```python\n",
    "# Example implementation with Firebase and FastAPI\n",
    "from fastapi import FastAPI, Depends, HTTPException, status\n",
    "from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n",
    "import firebase_admin\n",
    "from firebase_admin import auth, credentials\n",
    "import jwt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Firebase Admin SDK\n",
    "cred = credentials.Certificate(\"path/to/firebase-credentials.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "\n",
    "# JWT configuration\n",
    "SECRET_KEY = \"your-secret-key\"  # Store securely in environment variables\n",
    "ALGORITHM = \"HS256\"\n",
    "ACCESS_TOKEN_EXPIRE_MINUTES = 60\n",
    "\n",
    "# Security scheme for FastAPI\n",
    "security = HTTPBearer()\n",
    "\n",
    "# Verify Firebase token\n",
    "async def verify_firebase_token(credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    try:\n",
    "        token = credentials.credentials\n",
    "        decoded_token = auth.verify_id_token(token)\n",
    "        return decoded_token\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_401_UNAUTHORIZED,\n",
    "            detail=f\"Invalid authentication credentials: {str(e)}\",\n",
    "            headers={\"WWW-Authenticate\": \"Bearer\"},\n",
    "        )\n",
    "\n",
    "# Create custom JWT\n",
    "def create_access_token(data: dict, expires_delta: timedelta = None):\n",
    "    to_encode = data.copy()\n",
    "    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))\n",
    "    to_encode.update({\"exp\": expire})\n",
    "    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\n",
    "    return encoded_jwt\n",
    "```\n"
   ],
   "id": "840afc4a894c7545"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. AI Interaction Services\n",
    "\n",
    "The core of our application is the AI chat functionality. We'll implement this using Vertex AI's Gemini models.\n",
    "\n",
    "### 3.1 Vertex AI Integration\n",
    "\n",
    "We'll use Google Cloud's Vertex AI to access Gemini models. The free tier and credits for new accounts will help us implement this cost-effectively.\n",
    "\n",
    "```python\n",
    "# Example implementation for Vertex AI Gemini integration\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "import vertexai\n",
    "import asyncio\n",
    "\n",
    "class AIService:\n",
    "    def __init__(self):\n",
    "        # Initialize Vertex AI with project and location\n",
    "        vertexai.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "        # Initialize the Gemini model\n",
    "        self.model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "    async def create_chat_session(self, system_instruction):\n",
    "        \"\"\"Create a new chat session with the specified system instruction.\"\"\"\n",
    "        chat = self.model.start_chat(\n",
    "            context=system_instruction\n",
    "        )\n",
    "        return chat\n",
    "\n",
    "    async def generate_response(self, chat: ChatSession, message: str):\n",
    "        \"\"\"Generate a streaming response from Gemini.\"\"\"\n",
    "        response = chat.send_message_streaming(message)\n",
    "        return response\n",
    "```\n",
    "\n",
    "### 3.2 Streaming Implementation\n",
    "\n",
    "To support the frontend's streaming capability:\n",
    "\n",
    "```python\n",
    "# Streaming implementation with FastAPI\n",
    "from fastapi import FastAPI, WebSocket\n",
    "from fastapi.responses import StreamingResponse\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "ai_service = AIService()\n",
    "\n",
    "@app.websocket(\"/api/v1/chat/stream\")\n",
    "async def chat_websocket(websocket: WebSocket):\n",
    "    await websocket.accept()\n",
    "\n",
    "    try:\n",
    "        # Receive and parse the initial message\n",
    "        data = await websocket.receive_text()\n",
    "        request_data = json.loads(data)\n",
    "\n",
    "        # Extract parameters\n",
    "        message = request_data.get(\"message\")\n",
    "        persona_id = request_data.get(\"personaId\")\n",
    "\n",
    "        # Get system instruction for the persona\n",
    "        system_instruction = await get_system_instruction(persona_id)\n",
    "\n",
    "        # Create chat session\n",
    "        chat = await ai_service.create_chat_session(system_instruction)\n",
    "\n",
    "        # Generate streaming response\n",
    "        response_stream = await ai_service.generate_response(chat, message)\n",
    "\n",
    "        # Stream the response to the client\n",
    "        for chunk in response_stream:\n",
    "            await websocket.send_text(chunk)\n",
    "\n",
    "        # Send end marker\n",
    "        await websocket.send_text(\"[DONE]\")\n",
    "\n",
    "    except Exception as e:\n",
    "        await websocket.send_text(f\"Error: {str(e)}\")\n",
    "    finally:\n",
    "        await websocket.close()\n",
    "```\n"
   ],
   "id": "91d1258c6a303373"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Content Processing Pipeline\n",
    "\n",
    "For processing uploaded files and URLs, we'll create an asynchronous pipeline using Cloud Functions and Pub/Sub.\n",
    "\n",
    "### 4.1 File Upload & Processing\n",
    "\n",
    "```python\n",
    "# File upload endpoint in FastAPI\n",
    "from fastapi import UploadFile, File, BackgroundTasks\n",
    "from google.cloud import storage, pubsub_v1\n",
    "import uuid\n",
    "\n",
    "# Initialize GCS client\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(\"synapse-od-uploads\")\n",
    "\n",
    "# Initialize Pub/Sub publisher\n",
    "publisher = pubsub_v1.PublisherClient()\n",
    "topic_path = publisher.topic_path(\"your-project-id\", \"file-processing\")\n",
    "\n",
    "@app.post(\"/api/v1/upload/file\")\n",
    "async def upload_file(\n",
    "    file: UploadFile = File(...),\n",
    "    background_tasks: BackgroundTasks = None,\n",
    "    current_user: dict = Depends(get_current_user)\n",
    "):\n",
    "    # Generate a unique job ID\n",
    "    job_id = str(uuid.uuid4())\n",
    "\n",
    "    # Create a GCS blob and upload the file\n",
    "    blob_name = f\"{current_user['uid']}/{job_id}/{file.filename}\"\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Read the file and upload to GCS\n",
    "    contents = await file.read()\n",
    "    blob.upload_from_string(contents)\n",
    "\n",
    "    # Publish a message to Pub/Sub to trigger processing\n",
    "    message_data = {\n",
    "        \"job_id\": job_id,\n",
    "        \"user_id\": current_user[\"uid\"],\n",
    "        \"file_path\": blob_name,\n",
    "        \"file_name\": file.filename,\n",
    "        \"file_type\": file.content_type,\n",
    "    }\n",
    "\n",
    "    # Convert message data to JSON and publish\n",
    "    publisher.publish(\n",
    "        topic_path, \n",
    "        data=json.dumps(message_data).encode(\"utf-8\")\n",
    "    )\n",
    "\n",
    "    # Return the job ID for status checking\n",
    "    return {\"job_id\": job_id, \"status\": \"processing\"}\n",
    "```\n",
    "\n",
    "### 4.2 Cloud Function for File Processing\n",
    "\n",
    "```python\n",
    "# Cloud Function to process uploaded files\n",
    "import functions_framework\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import os\n",
    "\n",
    "@functions_framework.cloud_event\n",
    "def process_file(cloud_event):\n",
    "    # Parse the Pub/Sub message\n",
    "    pubsub_message = base64.b64decode(cloud_event.data[\"message\"][\"data\"]).decode(\"utf-8\")\n",
    "    message_data = json.loads(pubsub_message)\n",
    "\n",
    "    # Extract information\n",
    "    job_id = message_data[\"job_id\"]\n",
    "    user_id = message_data[\"user_id\"]\n",
    "    file_path = message_data[\"file_path\"]\n",
    "    file_name = message_data[\"file_name\"]\n",
    "    file_type = message_data[\"file_type\"]\n",
    "\n",
    "    # Process the file based on type\n",
    "    if file_type.startswith(\"text/\"):\n",
    "        process_text_file(file_path)\n",
    "    elif file_type.startswith(\"image/\"):\n",
    "        process_image_file(file_path)\n",
    "    elif file_type.startswith(\"application/pdf\"):\n",
    "        process_pdf_file(file_path)\n",
    "    # Add more file type handlers as needed\n",
    "\n",
    "    # Update job status in database\n",
    "    update_job_status(job_id, \"completed\")\n",
    "```\n"
   ],
   "id": "bcc144cd617ed76e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Child Bot Management\n",
    "\n",
    "We'll implement a system for creating, storing, and managing child bots.\n",
    "\n",
    "### 5.1 Child Bot Data Model\n",
    "\n",
    "```python\n",
    "# MongoDB model for child bots\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "class ChildBot(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
    "    user_id: str\n",
    "    name: str\n",
    "    icon: str\n",
    "    keywords: List[str]\n",
    "    system_instruction: str\n",
    "    base_persona_id: Optional[str] = None\n",
    "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "    updated_at: datetime = Field(default_factory=datetime.utcnow)\n",
    "    usage_count: int = 0\n",
    "    performance_metrics: dict = Field(default_factory=dict)\n",
    "```\n",
    "\n",
    "### 5.2 Child Bot API Implementation\n",
    "\n",
    "```python\n",
    "# Child bot endpoints\n",
    "from fastapi import APIRouter, Depends, HTTPException\n",
    "from typing import List\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "@router.post(\"/child-bots\", response_model=ChildBot)\n",
    "async def create_child_bot(\n",
    "    child_bot: ChildBotCreate,\n",
    "    current_user: dict = Depends(get_current_user)\n",
    "):\n",
    "    # Create a new child bot\n",
    "    new_bot = ChildBot(\n",
    "        user_id=current_user[\"uid\"],\n",
    "        name=child_bot.name,\n",
    "        icon=child_bot.icon,\n",
    "        keywords=child_bot.keywords,\n",
    "        system_instruction=child_bot.system_instruction,\n",
    "        base_persona_id=child_bot.base_persona_id\n",
    "    )\n",
    "\n",
    "    # Save to database\n",
    "    result = await db.child_bots.insert_one(new_bot.dict())\n",
    "    new_bot.id = str(result.inserted_id)\n",
    "\n",
    "    return new_bot\n",
    "\n",
    "@router.get(\"/child-bots\", response_model=List[ChildBot])\n",
    "async def list_child_bots(current_user: dict = Depends(get_current_user)):\n",
    "    # Get all child bots for the current user\n",
    "    cursor = db.child_bots.find({\"user_id\": current_user[\"uid\"]})\n",
    "    bots = await cursor.to_list(length=100)\n",
    "    return bots\n",
    "\n",
    "@router.get(\"/child-bots/{bot_id}\", response_model=ChildBot)\n",
    "async def get_child_bot(\n",
    "    bot_id: str,\n",
    "    current_user: dict = Depends(get_current_user)\n",
    "):\n",
    "    # Get a specific child bot\n",
    "    bot = await db.child_bots.find_one({\n",
    "        \"id\": bot_id,\n",
    "        \"user_id\": current_user[\"uid\"]\n",
    "    })\n",
    "\n",
    "    if not bot:\n",
    "        raise HTTPException(status_code=404, detail=\"Child bot not found\")\n",
    "\n",
    "    return bot\n",
    "```\n"
   ],
   "id": "fb30a50492192785"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Admin Analytics & Monitoring\n",
    "\n",
    "We'll implement the admin dashboard backend using Cloud Logging and a MongoDB collection for query logs.\n",
    "\n",
    "### 6.1 Query Logging System\n",
    "\n",
    "```python\n",
    "# Query logging middleware for FastAPI\n",
    "from fastapi import Request\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def log_queries(request: Request, call_next):\n",
    "    # Get the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Process the request\n",
    "    response = await call_next(request)\n",
    "\n",
    "    # Calculate processing time\n",
    "    process_time = time.time() - start_time\n",
    "\n",
    "    # Log only chat API calls\n",
    "    if request.url.path.startswith(\"/api/v1/chat\") and request.method == \"POST\":\n",
    "        try:\n",
    "            # Get request body (need to create a copy as it might have been consumed)\n",
    "            body = await request.body()\n",
    "            body_json = json.loads(body)\n",
    "\n",
    "            # Extract relevant information\n",
    "            user_id = request.state.user.uid if hasattr(request.state, \"user\") else \"anonymous\"\n",
    "            persona_id = body_json.get(\"personaId\", \"unknown\")\n",
    "            query_text = body_json.get(\"message\", \"\")\n",
    "            child_bot_id = body_json.get(\"childBotId\", None)\n",
    "\n",
    "            # Create log entry\n",
    "            log_entry = {\n",
    "                \"timestamp\": datetime.utcnow(),\n",
    "                \"user_id\": user_id,\n",
    "                \"persona_id\": persona_id,\n",
    "                \"child_bot_id\": child_bot_id,\n",
    "                \"query_text\": query_text,\n",
    "                \"response_text\": \"Response captured separately\",  # Will be updated later\n",
    "                \"processing_time\": process_time,\n",
    "                \"status\": \"Normal\",\n",
    "                \"quality_score\": \"unreviewed\"\n",
    "            }\n",
    "\n",
    "            # Save log to database\n",
    "            await db.query_logs.insert_one(log_entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log error but don't fail the request\n",
    "            logger.error(f\"Error logging query: {str(e)}\")\n",
    "\n",
    "    return response\n",
    "```\n",
    "\n",
    "### 6.2 Admin Analytics Endpoints\n",
    "\n",
    "```python\n",
    "# Admin analytics endpoints\n",
    "from fastapi import APIRouter, Depends\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "router = APIRouter()\n",
    "\n",
    "@router.get(\"/analytics\")\n",
    "async def get_analytics(\n",
    "    current_user: dict = Depends(get_admin_user),  # Custom dependency to check admin role\n",
    "    days: int = 7\n",
    "):\n",
    "    # Calculate date range\n",
    "    end_date = datetime.utcnow()\n",
    "    start_date = end_date - timedelta(days=days)\n",
    "\n",
    "    # Get total users\n",
    "    total_users = await db.users.count_documents({})\n",
    "\n",
    "    # Get active users in date range\n",
    "    active_users = await db.users.count_documents({\n",
    "        \"last_active\": {\"$gte\": start_date}\n",
    "    })\n",
    "\n",
    "    # Get total API calls in date range\n",
    "    total_api_calls = await db.query_logs.count_documents({\n",
    "        \"timestamp\": {\"$gte\": start_date, \"$lte\": end_date}\n",
    "    })\n",
    "\n",
    "    # Get total child bots created\n",
    "    total_child_bots = await db.child_bots.count_documents({})\n",
    "\n",
    "    # Calculate average response time\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"timestamp\": {\"$gte\": start_date, \"$lte\": end_date}}},\n",
    "        {\"$group\": {\"_id\": None, \"avg_time\": {\"$avg\": \"$processing_time\"}}}\n",
    "    ]\n",
    "    result = await db.query_logs.aggregate(pipeline).to_list(length=1)\n",
    "    avg_response_time = result[0][\"avg_time\"] if result else 0\n",
    "\n",
    "    # Get API success rate\n",
    "    success_count = await db.query_logs.count_documents({\n",
    "        \"timestamp\": {\"$gte\": start_date, \"$lte\": end_date},\n",
    "        \"status\": {\"$ne\": \"Error\"}\n",
    "    })\n",
    "    success_rate = (success_count / total_api_calls * 100) if total_api_calls > 0 else 100\n",
    "\n",
    "    # Get top users by API calls\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"timestamp\": {\"$gte\": start_date, \"$lte\": end_date}}},\n",
    "        {\"$group\": {\"_id\": \"$user_id\", \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 10},\n",
    "        {\"$lookup\": {\n",
    "            \"from\": \"users\",\n",
    "            \"localField\": \"_id\",\n",
    "            \"foreignField\": \"uid\",\n",
    "            \"as\": \"user_info\"\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"user_id\": \"$_id\",\n",
    "            \"count\": 1,\n",
    "            \"name\": {\"$arrayElemAt\": [\"$user_info.name\", 0]},\n",
    "            \"email\": {\"$arrayElemAt\": [\"$user_info.email\", 0]}\n",
    "        }}\n",
    "    ]\n",
    "    top_users = await db.query_logs.aggregate(pipeline).to_list(length=10)\n",
    "\n",
    "    return {\n",
    "        \"summary\": {\n",
    "            \"total_users\": total_users,\n",
    "            \"active_users\": active_users,\n",
    "            \"total_api_calls\": total_api_calls,\n",
    "            \"total_child_bots\": total_child_bots,\n",
    "            \"avg_response_time\": avg_response_time,\n",
    "            \"api_success_rate\": success_rate\n",
    "        },\n",
    "        \"top_users\": top_users,\n",
    "        # Additional statistics can be added here\n",
    "    }\n",
    "```\n"
   ],
   "id": "985352924492380e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Security Implementation\n",
    "\n",
    "Security is a critical aspect of our application. We'll implement the following security measures:\n",
    "\n",
    "### 7.1 API Security\n",
    "\n",
    "```python\n",
    "# Security middleware\n",
    "from fastapi import FastAPI, Request, HTTPException\n",
    "import time\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Rate limiting middleware\n",
    "@app.middleware(\"http\")\n",
    "async def rate_limit_middleware(request: Request, call_next):\n",
    "    # Get client IP\n",
    "    client_ip = request.client.host\n",
    "\n",
    "    # Check if client has exceeded rate limit\n",
    "    if await is_rate_limited(client_ip):\n",
    "        raise HTTPException(status_code=429, detail=\"Too many requests\")\n",
    "\n",
    "    # Process the request\n",
    "    response = await call_next(request)\n",
    "\n",
    "    return response\n",
    "\n",
    "# Input validation middleware\n",
    "@app.middleware(\"http\")\n",
    "async def validate_input(request: Request, call_next):\n",
    "    # For POST/PUT requests, validate the JSON body\n",
    "    if request.method in [\"POST\", \"PUT\"]:\n",
    "        try:\n",
    "            # Get request body\n",
    "            body = await request.body()\n",
    "            if body:\n",
    "                # Parse JSON\n",
    "                json.loads(body)\n",
    "        except json.JSONDecodeError:\n",
    "            raise HTTPException(status_code=400, detail=\"Invalid JSON\")\n",
    "\n",
    "    # Process the request\n",
    "    response = await call_next(request)\n",
    "\n",
    "    return response\n",
    "```\n",
    "\n",
    "### 7.2 Data Security\n",
    "\n",
    "```python\n",
    "# Example for encrypting sensitive data\n",
    "from cryptography.fernet import Fernet\n",
    "import os\n",
    "\n",
    "# Generate a key or load from environment\n",
    "if not os.path.exists(\"encryption_key.key\"):\n",
    "    key = Fernet.generate_key()\n",
    "    with open(\"encryption_key.key\", \"wb\") as key_file:\n",
    "        key_file.write(key)\n",
    "else:\n",
    "    with open(\"encryption_key.key\", \"rb\") as key_file:\n",
    "        key = key_file.read()\n",
    "\n",
    "# Create a cipher suite\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "def encrypt_data(data: str) -> str:\n",
    "    \"\"\"Encrypt sensitive data.\"\"\"\n",
    "    return cipher_suite.encrypt(data.encode()).decode()\n",
    "\n",
    "def decrypt_data(encrypted_data: str) -> str:\n",
    "    \"\"\"Decrypt sensitive data.\"\"\"\n",
    "    return cipher_suite.decrypt(encrypted_data.encode()).decode()\n",
    "```\n"
   ],
   "id": "4c2c46277c2ea57d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Deployment & DevOps\n",
    "\n",
    "We'll use GitHub Actions for CI/CD and deploy to Google Cloud Run for a serverless architecture.\n",
    "\n",
    "### 8.1 CI/CD Pipeline with GitHub Actions\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/deploy.yml\n",
    "name: Deploy to Google Cloud Run\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main ]\n",
    "\n",
    "jobs:\n",
    "  deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "    - uses: actions/checkout@v2\n",
    "\n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v2\n",
    "      with:\n",
    "        python-version: '3.11'\n",
    "\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install -r requirements.txt\n",
    "        pip install pytest\n",
    "\n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        pytest\n",
    "\n",
    "    - name: Setup Google Cloud SDK\n",
    "      uses: google-github-actions/setup-gcloud@v0\n",
    "      with:\n",
    "        project_id: ${{ secrets.GCP_PROJECT_ID }}\n",
    "        service_account_key: ${{ secrets.GCP_SA_KEY }}\n",
    "\n",
    "    - name: Build and push Docker image\n",
    "      run: |\n",
    "        gcloud builds submit --tag gcr.io/${{ secrets.GCP_PROJECT_ID }}/synapse-od-backend\n",
    "\n",
    "    - name: Deploy to Cloud Run\n",
    "      run: |\n",
    "        gcloud run deploy synapse-od-backend \\\n",
    "          --image gcr.io/${{ secrets.GCP_PROJECT_ID }}/synapse-od-backend \\\n",
    "          --platform managed \\\n",
    "          --region us-central1 \\\n",
    "          --allow-unauthenticated\n",
    "```\n",
    "\n",
    "### 8.2 Dockerization\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements and install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY . .\n",
    "\n",
    "# Set environment variables\n",
    "ENV PORT=8080\n",
    "\n",
    "# Run the application\n",
    "CMD uvicorn app.main:app --host 0.0.0.0 --port ${PORT}\n",
    "```\n"
   ],
   "id": "3e75773d8aeda7e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Vertex AI Integration for Model Training\n",
    "\n",
    "We'll use Google Cloud's Vertex AI to train and deploy custom models, taking advantage of the free credits for new accounts.\n",
    "\n",
    "### 9.1 Model Training Pipeline\n",
    "\n",
    "```python\n",
    "# Model training with Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def train_custom_model(dataset_uri, model_name, training_config):\n",
    "    # Initialize Vertex AI SDK\n",
    "    aiplatform.init(project=\"your-project-id\", location=\"us-central1\")\n",
    "\n",
    "    # Create a dataset\n",
    "    dataset = aiplatform.TextDataset.create(\n",
    "        display_name=f\"{model_name}_dataset\",\n",
    "        gcs_source=dataset_uri\n",
    "    )\n",
    "\n",
    "    # Configure the training job\n",
    "    job = aiplatform.CustomTrainingJob(\n",
    "        display_name=f\"{model_name}_training\",\n",
    "        script_path=\"trainer/task.py\",\n",
    "        container_uri=\"gcr.io/cloud-aiplatform/training/tf-cpu.2-8:latest\",\n",
    "        requirements=[\"tensorflow==2.8.0\", \"transformers==4.18.0\"],\n",
    "        model_serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-8:latest\",\n",
    "    )\n",
    "\n",
    "    # Start the training job\n",
    "    model = job.run(\n",
    "        dataset=dataset,\n",
    "        model_display_name=model_name,\n",
    "        args=training_config\n",
    "    )\n",
    "\n",
    "    return model\n",
    "```\n",
    "\n",
    "### 9.2 Model Deployment and Serving\n",
    "\n",
    "```python\n",
    "# Deploy model to Vertex AI Endpoint\n",
    "def deploy_model(model, machine_type=\"n1-standard-2\", min_replicas=1):\n",
    "    # Deploy model to an endpoint\n",
    "    endpoint = model.deploy(\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replicas,\n",
    "        max_replica_count=min_replicas,\n",
    "    )\n",
    "\n",
    "    return endpoint\n",
    "\n",
    "# Use deployed model for prediction\n",
    "async def predict_with_custom_model(endpoint, instances):\n",
    "    # Make prediction using deployed model\n",
    "    prediction = await endpoint.predict(instances=instances)\n",
    "    return prediction.predictions\n",
    "```\n"
   ],
   "id": "65b85926fcd3190f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Implementation Timeline\n",
    "\n",
    "### Phase 1: Core Infrastructure (Weeks 1-2)\n",
    "- Set up project structure\n",
    "- Configure Firebase authentication\n",
    "- Implement basic FastAPI endpoints\n",
    "- Set up MongoDB and connect to database\n",
    "\n",
    "### Phase 2: AI Integration (Weeks 3-4)\n",
    "- Implement Vertex AI Gemini integration\n",
    "- Create streaming response capability\n",
    "- Build persona management system\n",
    "- Test AI interaction flow\n",
    "\n",
    "### Phase 3: File Processing (Weeks 5-6)\n",
    "- Set up Cloud Storage for file uploads\n",
    "- Implement Pub/Sub messaging\n",
    "- Create Cloud Functions for file processing\n",
    "- Build URL processing microservice\n",
    "\n",
    "### Phase 4: Child Bot Management (Weeks 7-8)\n",
    "- Implement child bot creation/management API\n",
    "- Create system instruction generator\n",
    "- Set up versioning for child bots\n",
    "- Test child bot interactions\n",
    "\n",
    "### Phase 5: Admin Features (Weeks 9-10)\n",
    "- Implement query logging system\n",
    "- Build analytics dashboard API\n",
    "- Create API monitoring endpoints\n",
    "- Implement query QC system\n",
    "\n",
    "### Phase 6: Security & Optimization (Weeks 11-12)\n",
    "- Implement security middleware\n",
    "- Set up rate limiting\n",
    "- Configure CORS and input validation\n",
    "- Performance optimization\n",
    "\n",
    "### Phase 7: Deployment & Testing (Weeks 13-14)\n",
    "- Set up CI/CD pipeline\n",
    "- Deploy to Cloud Run\n",
    "- Comprehensive testing\n",
    "- Documentation\n"
   ],
   "id": "1cf8ad98ce613f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate a requirements.txt file\n",
    "requirements = [\n",
    "    \"fastapi==0.104.1\",\n",
    "    \"uvicorn==0.23.2\",\n",
    "    \"pydantic==2.4.2\",\n",
    "    \"firebase-admin==6.2.0\",\n",
    "    \"PyJWT==2.8.0\",\n",
    "    \"motor==3.3.1\",\n",
    "    \"python-multipart==0.0.6\",\n",
    "    \"google-cloud-storage==2.12.0\",\n",
    "    \"google-cloud-pubsub==2.18.4\",\n",
    "    \"google-cloud-logging==3.8.0\",\n",
    "    \"vertexai==0.0.1\",\n",
    "    \"cryptography==41.0.5\",\n",
    "    \"httpx==0.25.1\",\n",
    "    \"pytest==7.4.3\",\n",
    "    \"pytest-asyncio==0.21.1\",\n",
    "    \"pinecone-client==2.2.4\",\n",
    "    \"redis==5.0.1\",\n",
    "    \"langchain==0.0.335\",\n",
    "    \"transformers==4.35.2\",\n",
    "    \"youtube-transcript-api==0.6.1\",\n",
    "    \"beautifulsoup4==4.12.2\",\n",
    "    \"python-dotenv==1.0.0\",\n",
    "    \"gunicorn==21.2.0\"\n",
    "]\n",
    "\n",
    "print(\"\\n\".join(requirements))\n"
   ],
   "id": "e1bb39de975d52fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This backend roadmap provides a comprehensive plan for implementing the Synapse-OD platform using free cloud services and Vertex AI for model training. The architecture is designed to be:\n",
    "\n",
    "1. **Scalable**: Using serverless Cloud Run and microservices\n",
    "2. **Cost-Effective**: Leveraging free tiers and credits\n",
    "3. **Secure**: Implementing proper authentication and data protection\n",
    "4. **Maintainable**: Following modern code organization principles\n",
    "5. **Automated**: Using CI/CD for deployment and testing\n",
    "\n",
    "By following this roadmap, we can efficiently build a robust backend that supports all the features outlined in the README_GUIDE.md while prioritizing backend implementation and maximizing automation.\n"
   ],
   "id": "9e01ef2c7f34ce23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
